#!/usr/bin/python
"""
Function to cross-correlate templates generated by template_gen function with
data and output the detecitons.  The main component of this script is the
normxcorr2 function from the openCV image processing package.  This is a highly
optimized and accurate normalized cross-correlation routine.  The details of
this code can be found here:
    http://www.cs.ubc.ca/research/deaton/remarks_ncc.html
The cpp code was first tested using the Matlab mex wrapper, and has since been
ported to a python callable dynamic library.

Part of the EQcorrscan module to integrate seisan nordic files into a full
cross-channel correlation for detection routine.
EQcorrscan is a python module designed to run match filter routines for
seismology, within it are routines for integration to seisan and obspy.
With obspy integration (which is necessary) all main waveform formats can be
read in and output.

This main section contains a script, LFE_search.py which demonstrates the usage
of the built in functions from template generation from picked waveforms
through detection by match filter of continuous data to the generation of lag
times to be used for relative locations.

The match-filter routine described here was used a previous Matlab code for the
Chamberlain et al. 2014 G-cubed publication.  The basis for the lag-time
generation section is outlined in Hardebeck & Shelly 2011, GRL.

Code generated by Calum John Chamberlain of Victoria University of Wellington,
2015.

All rights reserved.

Pre-requisites:
    gcc             - for the installation of the openCV correlation routine
    python-joblib   - used for parallel processing
    python-obspy    - used for lots of common seismological processing
                    - requires:
                        numpy
                        scipy
                        matplotlib
    python-pylab    - used for plotting
"""
import numpy as np

class DETECTION(object):
    """
    Information required for a full detection based on cross-channel
    correlation sums.

    Attributes:
        :type template_name: str
        :param template_name: The name of the template for which this detection\
        was made
        :type detect_time: :class: 'obspy.UTCDateTime'
        :param detect_time: Time of detection as an obspy UTCDateTime object
        :type no_chans: int
        :param no_chans: The number of channels for which the cross-channel\
        correlation sum was calculated over.
        :type chans: list of str
        :param chans: List of stations for the detection
        :type cccsum_val: float
        :param cccsum_val: The raw value of the cross-channel correlation sum\
        for this detection.
        :type threshold: float
        :param threshold: The value of the threshold used for this detection,\
        will be the raw threshold value related to the cccsum.
        :type typeofdet: str
        :param typeofdet: Type of detection, STA, corr, bright
    """
    detectioncount=0
    def __init__(self, template_name, detect_time,
                 no_chans, detect_val,
                 threshold, typeofdet,
                 chans=None):

        self.template_name=template_name
        self.detect_time=detect_time
        self.no_chans=no_chans
        self.chans=chans
        self.detect_val=detect_val
        self.threshold=threshold
        self.typeofdet=typeofdet
        self.detectioncount+=1

def normxcorr2(template, image):
    """
    Base function to call the c++ correlation routine from the openCV image
    processing suite.  Requires you to have installed the openCV python
    bindings, which can be downloaded on Linux machines using:
        sudo apt-get install python-openCV
    Here we use the cv2.TM_CCOEFF_NORMED method within openCV to give the
    normalized cross-correaltion.  Documentation on this function can be
    found here:
        http://docs.opencv.org/modules/imgproc/doc/object_detection.html?highlight=matchtemplate#cv2.matchTemplate

    :type template: :class: 'numpy.array'
    :type image: :class: 'numpy.array'
    :param image: Requires two numpy arrays, the template and the image to scan
    the template through.  The order of these matters, if you put the template
    after the imag you will get a reversed correaltion matrix

    :return: New :class: 'numpy.array' object of the correlation values for the
    correaltion of the image with the template.
    """
    import cv2
    # Check that we have been passed numpy arrays
    if type(template) != np.ndarray or type(image) != np.ndarray:
        print 'You hav not provided numpy arrays, I will not convert them'
        return 'NaN'
    # Convert numpy arrays to float 32
    cv_template=template.astype(np.float32)
    cv_image=image.astype(np.float32)
    ccc=cv2.matchTemplate(cv_image,cv_template,cv2.TM_CCOEFF_NORMED)
    return ccc

def _channel_loop(tr, stream, delay):
    """
    Intermediate step which can be run in parallel to correlate a single
    channel template with a single channel of data only if the channel and
    template match header values.  Written to allow parallelisation at this
    step.

    :type tr: :class: 'obspy.Trace'
    :param tr: Single trace of template seismic data
    :type chan: :class: 'obspy.Trace'
    :param chan: Single trace of day-long seismic data to be used as an image
    :type delay: float
    :param delay: time in seconds to apply a lag to the data by.

    :return: :class: 'numpy.array' of single channel cross-correlation values
    """
    from par import match_filter_par as matchdef
    ccc=np.array([0.0]*len(stream[0].data)) # Set default value for
                                            # cross-channel correlation in
                                            # case there are no data that
                                            # match our channels.
    for chan in stream: # This allows only correlations from channels in both the
                        # template and stream to be correlated
        if chan.stats.station == tr.stats.station and\
            chan.stats.channel == tr.stats.channel:
            # Generate an array of zeros to pad the data with
            pad=np.array([0]*int(delay*tr.stats.sampling_rate))
            # Apply shift to data
            image=np.append(chan.data,pad)[len(pad):]
            if matchdef.debug>=4:
                # If we really want to debug we should check that the first
                # section of data (the pad) is really a pad
                import matplotlib.pylab as plt
                fig=plt.figure()
                ax1=fig.add_subplot(211)
                plt.title('Last 60s of data')
                ax1.plot(image[len(image)-60*chan.stats.sampling_rate:])
                ax2=fig.add_subplot(212)
                plt.title('First 60s of data')
                ax2.plot(image[0:60*chan.stats.sampling_rate])
                fig.suptitle(tr.stats.station+'.'+tr.stats.channel+' Padded by '+str(delay)+'s')
                plt.show()
            # Return a numpy array as ccc
            # print 'Running the correlation for '+tr.stats.station+'.'+\
                    # tr.stats.channel
            ccc=(normxcorr2(tr.data, image))
            # Check which channels are not correlating properly --- TESTING DEBUG
            if matchdef.debug >= 3:
                print '********* DEBUG:  '+chan.stats.station+'.'+chan.stats.channel+' ccc: '+str(max(ccc))
            if matchdef.debug == 5:
                f=open('debug_output/'+chan.stats.station+'.'+chan.stats.channel+'_ccc.txt','w')
                for correlation in ccc:
                    f.write(str(correlation)+'\n')
                f.close()
            return ccc # only return the correlation values if they have been filled
    return np.array([0.0])

def _template_loop(templates, delays, stream, plotvar):
    """
    Higher level routine to handle correlation of a Stream of day-long data
    channels with a series of templates.  The idea is to run this in parallel
    as these correaltions can be run incredibly quickly at little cost.
    The most memory efficient way to run this would be to run the correlations
    in parallel for each channel.

    :type templates: :class: 'obspy.Stream'
    :param template: A list of templates, where each one should be an
    obspy.Stream object containing multiple traces of seismic data and the
    relevant header information.
    :type delays: float
    :param delays: A list of lists of delays order in the same way as the
    templates, e.g. delays[1][1] referes to the first trace in templates[1]
    :type stream: :class: 'obspy.Stream'
    :param stream: A single obspy.Stream object containing daylong seismic data
    to be correlated through using the templates.  This is in effect the image

    :return: New list of :class: 'numpy.array' objects.  These will contain the
    correlation sums for each template for this day of data.
    :return: list of ints as number of channels used for each cross-correlation
    """
    from joblib import Parallel, delayed
    from obspy import Trace
    import time
    from par import match_filter_par as matchdef
    # Initialise the list of correlation sums.
    cccsums=[]
    no_chans=[]
    # Start an indexing system to keep track of which template we are running
    i=0
    for template in templates:
        temp_delays=delays[i] # Delays for all channels for this template
        # Initialise a further indexing system to keep track of which stream
        # we are processing
        cccs=[]
        tic=time.clock()
        # Linear
        if matchdef.debug>=4:
            print 'At this debug level I have to run in a linear loop'
            for j in xrange(0,len(template)):
                cccs.append(_channel_loop(template[j], stream, temp_delays[j]))
        # Parallel
        else:
            cccs=Parallel(n_jobs=matchdef.cores)(delayed(_channel_loop)(template[j],
                                                                        stream,
                                                                        temp_delays[j])\
                                                 for j in xrange(0, len(template)))
        toc=time.clock()
        print 'Running the correlation loop took: '+str(toc-tic)+' s'
        # Work out how many channels were actually used.
        # Remove zero rows
        kchans=0
        if 'cccsum' in locals():
            del cccsum
        for ccc in cccs:
            if not np.shape(ccc)[0]==1:
                kchans+=1
                if not 'cccsum' in locals():
                    cccsum=np.reshape(ccc, (1,len(ccc)))
                else:
                    cccsum=np.append(cccsum, \
                                     np.reshape(ccc, (1,len(ccc))), axis=0)
        if matchdef.debug >=2:
            print 'I have correlated with '+str(kchans)+' channels'
        if 'cccsum' in locals():
            cccsum=np.sum(cccsum, axis=0)
            no_chans.append(kchans)
            cccsum=cccsum.reshape((len(cccsum),1))
            # Pad the cccsum to daylong length as done in matlab codes, it should
            # be noted that this correlation method does not allow for partical
            # correlations at the edge of the image.
            cccsum=np.append(cccsum,np.array([0.0]*(len(stream[0].data)-len(cccsum))))
            cccsum=cccsum.reshape((len(cccsum),))
            cccsums.append(cccsum)
            # Increase our index by one when the template is complete
        else:
            cccsums.append(np.array([0.0]))
            no_chans.append(0)
        i+=1
    return cccsums, no_chans

def match_filter(template_names, templates, delays, stream, threshold,
                 threshold_type, trig_int, plotvar):
    """
    Over-arching code to run the correlations of given templates with a day of
    seismic data and output the detections based on a given threshold.

    :type templates: list :class: 'obspy.Stream'
    :param templates: A list of templates of which each template is a Stream of
    obspy traces containing seismic data and header information.
    :type stream: :class: 'obspy.Stream'
    :param stream: An obspy.Stream object containing all the data available and
    required for the correlations with templates given.  For efficiency this
    should contain no excess traces which are not in one or more of the
    templates.
    :type threshold: float
    :param threshold: A threshold value set based on the threshold_type
    :type threshold_type: str
    :param threshold:type: The type of threshold to be used, can be MAD,
    absolute or av_chan_corr.
    MAD threshold is calculated as the
    threshold*(mean(abs(cccsum))) where cccsum is the cross-correlation sum
    for a given template.
    absolute threhsold is a true absolute threshold based on the cccsum value
    av_chan_corr is based on the mean values of single-channel
    cross-correlations assuming all data are present as required for the
    template, e.g. av_chan_corr_thresh=threshold*(cccsum/len(template)) where
    template is a single template from the input and the length is the number
    of channels within this template.

    :return: :class: 'DETECTIONS' detections for each channel formatted as
    :class: 'obspy.UTCDateTime' objects.

    """
    from utils import findpeaks, EQcorrscan_plotting
    import time, copy
    from obspy import Trace
    from par import match_filter_par as matchdef
    # Debug option to confirm that the channel names match those in the templates
    if matchdef.debug>=2:
        template_stachan=[]
        data_stachan=[]
        for template in templates:
            for tr in template:
                template_stachan.append(tr.stats.station+'.'+tr.stats.channel)
        for tr in stream:
            data_stachan.append(tr.stats.station+'.'+tr.stats.channel)
        template_stachan=list(set(template_stachan))
        data_stachan=list(set(data_stachan))
        print 'I have template info for these stations:'
        print template_stachan
        print 'I have daylong data for these stations:'
        print data_stachan
    # Call the _template_loop function to do all the correlation work
    outtic=time.clock()
    [cccsums, no_chans]=_template_loop(templates, delays, stream, plotvar)
    if len(cccsums[0])==0:
        raise ValueError('Correlation has not run, zero length cccsum')
    outtoc=time.clock()
    print 'Looping over templates took: '+str(outtoc-outtic)+' s'
    i=0
    detections=[]
    for cccsum in cccsums:
        template=templates[i]
        if threshold_type=='MAD':
            rawthresh=threshold*np.median(np.abs(cccsum))
        elif threshold_type=='absolute':
            rawthresh=threshold
        elif threshold=='av_chan_corr':
            rawthresh=threshold*(cccsum/len(template))
        else:
            print 'You have not selected the correct threshold type, I will use MAD as I like it'
            rawthresh=threshold*np.mean(np.abs(cccsum))
        # Findpeaks returns a list of tuples in the form [(cccsum, sample)]
        print 'Threshold is set at: '+str(rawthresh)
        print 'Max of data is: '+str(max(cccsum))
        # Set up a trace object for the cccsum as this is easier to plot and
        # maintins timeing
        if plotvar:
            # Downsample for plotting
            stream_plot=copy.deepcopy(stream[0])
            stream_plot.resample(25)
            cccsum_plot=Trace(cccsum)
            cccsum_plot.stats.sampling_rate=stream[0].stats.sampling_rate
            cccsum_plot=cccsum_plot.resample(25).data
            EQcorrscan_plotting.triple_plot(cccsum_plot, stream_plot, rawthresh, True,\
                                          'cccsum_plot_'+template_names[i]+'_'+\
                                          str(stream[0].stats.starttime.year)+'-'+\
                                          str(stream[0].stats.starttime.month)+'-'+\
                                          str(stream[0].stats.starttime.day)+'.pdf')
        tic=time.clock()
        if matchdef.debug>=3 and max(cccsum)>rawthresh:
            peaks=findpeaks.find_peaks2(cccsum, rawthresh, \
                                        trig_int*stream[0].stats.sampling_rate,\
                                        matchdef.debug, stream[0].stats.starttime,
                                        stream[0].stats.sampling_rate)
        elif max(cccsum)>rawthresh:
            peaks=findpeaks.find_peaks2(cccsum, rawthresh, \
                                        trig_int*stream[0].stats.sampling_rate,\
                                        matchdef.debug)
        else:
            print 'No peaks found above threshold'
            peaks=False
        toc=time.clock()
        print 'Finding peaks took: '+str(toc-tic)+' s'
        if peaks:
            for peak in peaks:
                detecttime=stream[0].stats.starttime+\
                            peak[1]/stream[0].stats.sampling_rate
                detections.append(DETECTION(template_names[i],
                                             detecttime,
                                             no_chans[i], peak[0], rawthresh,
                                             'corr'))
    i+=1

    return detections
